{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd0e4b32c4c655fa694298ff80f540860bd845c191a9c38f277b9165c7be10f4e8e",
   "display_name": "Python 3.8.8 64-bit ('cmpt733': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wide = pd.read_csv('../microservices/dash_app/wide.csv')\n",
    "df_wide['datetime'] = pd.to_datetime(df_wide['hour'], format='%Y-%m-%d %H:%M:%S')\n",
    "df_gamestop = df_wide.set_index('datetime')\n",
    "\n",
    "train_org_df = df_gamestop[df_gamestop.index.year == 2020]\n",
    "test_org_df = df_gamestop[df_gamestop.index.year == 2021]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose a feature set for training and testing \n",
    "feature_set_finn = [\"openprice\", \"highprice\", \"lowprice\", \"volume\", \"closeprice\"]\n",
    "\n",
    "feature_set_wide = [\n",
    "    \"avg_all_post_pos\",\n",
    "    \"avg_all_post_neg\",\n",
    "    \"avg_all_post_neu\",\n",
    "    \"cnt_all_user\",\n",
    "    \"cnt_all_tag\",\n",
    "    \"cnt_all_post\",\n",
    "    \"cnt_all_comments\",\n",
    "    \"avg_gme_post_pos\",\n",
    "    \"avg_gme_post_neg\",\n",
    "    \"avg_gme_post_neu\",\n",
    "    \"cnt_gme_user\",\n",
    "    \"cnt_gme_tag\",\n",
    "    \"cnt_gme_post\",\n",
    "    \"cnt_gme_comments\",\n",
    "    \"volume\",\n",
    "    \"openprice\",\n",
    "    \"highprice\",\n",
    "    \"lowprice\",\n",
    "    \"closeprice\"\n",
    "]\n",
    "feature_set_eng = [\n",
    "    \"avg_all_post_pos\",\n",
    "    \"avg_all_post_neg\",\n",
    "    \"avg_all_post_neu\",\n",
    "    \"cnt_all_user\",\n",
    "    \"cnt_all_tag\",\n",
    "    \"cnt_all_post\",\n",
    "    \"cnt_all_comments\",\n",
    "    \"avg_gme_post_pos\",\n",
    "    \"avg_gme_post_neg\",\n",
    "    \"avg_gme_post_neu\",\n",
    "    \"cnt_gme_user\",\n",
    "    \"cnt_gme_tag\",\n",
    "    \"cnt_gme_post\",\n",
    "    \"cnt_gme_comments\",\n",
    "    \"closeprice\"\n",
    "]\n",
    "\n",
    "feature_label_cols = feature_set_eng\n",
    "feature_cols = feature_label_cols[:-1]\n",
    "label_cols = feature_label_cols[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_org_df[feature_label_cols]\n",
    "test_df = test_org_df[feature_label_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(df, feature_set, scaler=None):\n",
    "    if scaler is None:\n",
    "        scaler = StandardScaler()\n",
    "        scaled_arr = scaler.fit_transform(df[feature_set])\n",
    "    else:\n",
    "        scaled_arr = scaler.transform(df[feature_set])\n",
    "    return scaled_arr, scaler\n",
    "\n",
    "def split(train_arr, train_ratio):\n",
    "    # split the data to train, validate\n",
    "    n = len(train_arr)\n",
    "    train_set = train_arr[:int(n*train_ratio)]\n",
    "    val_set = train_arr[int(n*train_ratio):]\n",
    "    return train_set, val_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(x_arr, y_arr):\n",
    "    x_tensor = torch.tensor(x_arr).float()\n",
    "    y_tensor = torch.tensor(y_arr).float()\n",
    "    num_features = x_tensor.shape[1]\n",
    "    dataset_seq = (x_tensor, y_tensor)\n",
    "    return dataset_seq, num_features\n",
    "\n",
    "def create_batch_set(dataset_seq, batch_size = 100):\n",
    "    x_tensor, y_tensor = dataset_seq\n",
    "    tensor_dataset = TensorDataset(x_tensor,y_tensor)\n",
    "    tensor_dataloader = DataLoader(tensor_dataset, batch_size, False)\n",
    "    return tensor_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_train = train_df[label_cols]\n",
    "label_test = test_df[label_cols]\n",
    "\n",
    "train_set, train_scaler = scale(train_df, feature_cols)\n",
    "target_set, _ = scale(test_df, feature_cols, train_scaler)\n",
    "train_set , val_set = split(train_set, 0.8)\n",
    "label_train , label_val = split(label_train, 0.8)\n",
    "\n",
    "train_seq, num_features = create_dataset(train_set, label_train)\n",
    "val_seq, _ = create_dataset(val_set, label_val)\n",
    "target_seq, _ = create_dataset(target_set, label_test)\n",
    "\n",
    "train_batches = create_batch_set(train_seq, batch_size=200)\n",
    "val_batches = create_batch_set(val_seq, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7fdac8006070>"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, seq_length, hidden_size=100, num_layers = 2, output_size=1):\n",
    "        super(LSTM, self).__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.seq_len = seq_length\n",
    "        \n",
    "        self.hidden_state = None\n",
    "        self.cell_state = None\n",
    "        self.hidden = (self.hidden_state, self.cell_state)\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=self.input_size,\n",
    "            hidden_size=self.hidden_size,\n",
    "            num_layers=self.num_layers,\n",
    "            dropout=0.2,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        self.linear = nn.Linear(self.hidden_size * self.seq_len, self.output_size)\n",
    "\n",
    "    def init_hidden(self, batch_size, device):\n",
    "        self.hidden_state = torch.zeros(self.num_layers, batch_size ,self.hidden_size).to(device)\n",
    "        self.cell_state = torch.zeros(self.num_layers, batch_size ,self.hidden_size).to(device)\n",
    "        self.hidden = (self.hidden_state, self.cell_state)\n",
    "\n",
    "    def forward(self, x):\n",
    "        lstm_out, self.hidden = self.lstm(\n",
    "                x,\n",
    "                self.hidden\n",
    "            )\n",
    "        outputs = self.linear(lstm_out.reshape(x.size(0),-1))\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}