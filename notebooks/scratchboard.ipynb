{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7692, 8)\n",
      "(6395, 8)\n",
      "(1297, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>close_price</th>\n",
       "      <th>high-price</th>\n",
       "      <th>low-price</th>\n",
       "      <th>open_price</th>\n",
       "      <th>status</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-04-09 13:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>3.70</td>\n",
       "      <td>3.72</td>\n",
       "      <td>3.450</td>\n",
       "      <td>3.450</td>\n",
       "      <td>ok</td>\n",
       "      <td>1586437200</td>\n",
       "      <td>319130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-09 14:00:00</th>\n",
       "      <td>1</td>\n",
       "      <td>3.86</td>\n",
       "      <td>3.90</td>\n",
       "      <td>3.685</td>\n",
       "      <td>3.700</td>\n",
       "      <td>ok</td>\n",
       "      <td>1586440800</td>\n",
       "      <td>620809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-09 15:00:00</th>\n",
       "      <td>2</td>\n",
       "      <td>4.06</td>\n",
       "      <td>4.08</td>\n",
       "      <td>3.800</td>\n",
       "      <td>3.865</td>\n",
       "      <td>ok</td>\n",
       "      <td>1586444400</td>\n",
       "      <td>1023287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-09 16:00:00</th>\n",
       "      <td>3</td>\n",
       "      <td>4.12</td>\n",
       "      <td>4.19</td>\n",
       "      <td>3.890</td>\n",
       "      <td>4.060</td>\n",
       "      <td>ok</td>\n",
       "      <td>1586448000</td>\n",
       "      <td>602239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-09 17:00:00</th>\n",
       "      <td>4</td>\n",
       "      <td>4.03</td>\n",
       "      <td>4.25</td>\n",
       "      <td>3.870</td>\n",
       "      <td>4.130</td>\n",
       "      <td>ok</td>\n",
       "      <td>1586451600</td>\n",
       "      <td>1006734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-31 19:00:00</th>\n",
       "      <td>4</td>\n",
       "      <td>18.99</td>\n",
       "      <td>19.47</td>\n",
       "      <td>18.910</td>\n",
       "      <td>19.470</td>\n",
       "      <td>ok</td>\n",
       "      <td>1609441200</td>\n",
       "      <td>792064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-31 20:00:00</th>\n",
       "      <td>5</td>\n",
       "      <td>18.81</td>\n",
       "      <td>19.03</td>\n",
       "      <td>18.800</td>\n",
       "      <td>18.980</td>\n",
       "      <td>ok</td>\n",
       "      <td>1609444800</td>\n",
       "      <td>1081315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-31 21:00:00</th>\n",
       "      <td>6</td>\n",
       "      <td>18.80</td>\n",
       "      <td>18.95</td>\n",
       "      <td>18.290</td>\n",
       "      <td>18.840</td>\n",
       "      <td>ok</td>\n",
       "      <td>1609448400</td>\n",
       "      <td>1270488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-31 22:00:00</th>\n",
       "      <td>6</td>\n",
       "      <td>18.80</td>\n",
       "      <td>18.95</td>\n",
       "      <td>18.290</td>\n",
       "      <td>18.840</td>\n",
       "      <td>ok</td>\n",
       "      <td>1609448400</td>\n",
       "      <td>1270488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-31 23:00:00</th>\n",
       "      <td>6</td>\n",
       "      <td>18.80</td>\n",
       "      <td>18.95</td>\n",
       "      <td>18.290</td>\n",
       "      <td>18.840</td>\n",
       "      <td>ok</td>\n",
       "      <td>1609448400</td>\n",
       "      <td>1270488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6395 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Unnamed: 0  close_price  high-price  low-price  \\\n",
       "datetime                                                              \n",
       "2020-04-09 13:00:00           0         3.70        3.72      3.450   \n",
       "2020-04-09 14:00:00           1         3.86        3.90      3.685   \n",
       "2020-04-09 15:00:00           2         4.06        4.08      3.800   \n",
       "2020-04-09 16:00:00           3         4.12        4.19      3.890   \n",
       "2020-04-09 17:00:00           4         4.03        4.25      3.870   \n",
       "...                         ...          ...         ...        ...   \n",
       "2020-12-31 19:00:00           4        18.99       19.47     18.910   \n",
       "2020-12-31 20:00:00           5        18.81       19.03     18.800   \n",
       "2020-12-31 21:00:00           6        18.80       18.95     18.290   \n",
       "2020-12-31 22:00:00           6        18.80       18.95     18.290   \n",
       "2020-12-31 23:00:00           6        18.80       18.95     18.290   \n",
       "\n",
       "                     open_price status   timestamp   volume  \n",
       "datetime                                                     \n",
       "2020-04-09 13:00:00       3.450     ok  1586437200   319130  \n",
       "2020-04-09 14:00:00       3.700     ok  1586440800   620809  \n",
       "2020-04-09 15:00:00       3.865     ok  1586444400  1023287  \n",
       "2020-04-09 16:00:00       4.060     ok  1586448000   602239  \n",
       "2020-04-09 17:00:00       4.130     ok  1586451600  1006734  \n",
       "...                         ...    ...         ...      ...  \n",
       "2020-12-31 19:00:00      19.470     ok  1609441200   792064  \n",
       "2020-12-31 20:00:00      18.980     ok  1609444800  1081315  \n",
       "2020-12-31 21:00:00      18.840     ok  1609448400  1270488  \n",
       "2020-12-31 22:00:00      18.840     ok  1609448400  1270488  \n",
       "2020-12-31 23:00:00      18.840     ok  1609448400  1270488  \n",
       "\n",
       "[6395 rows x 8 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load raw financial data\n",
    "# hourly resolution\n",
    "gamestop_data = pd.read_csv('../foobar/data/raw/stock_candle_60_2020-03-01_2021-03-01.csv')\n",
    "gamestop_data = gamestop_data.sort_values(by=['timestamp'], axis=0)\n",
    "gamestop_data['datetime'] = pd.to_datetime(gamestop_data['timestamp'], unit='s')\n",
    "gamestop_data = gamestop_data.set_index('datetime')\n",
    "\n",
    "# resmaple the data hourly and pad the gaps with the previous record\n",
    "gamestop_data = gamestop_data.resample('H', label='right').pad()\n",
    "print(gamestop_data.shape)\n",
    "\n",
    "train_data = gamestop_data[gamestop_data.index.year == 2020]\n",
    "short_squeeze_data = gamestop_data[gamestop_data.index.year == 2021]\n",
    "print(train_data.shape)\n",
    "print(short_squeeze_data.shape)\n",
    "\n",
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "open_price     float64\n",
      "high-price     float64\n",
      "low-price      float64\n",
      "volume           int64\n",
      "close_price    float64\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['open_price', 'high-price', 'low-price', 'volume', 'close_price']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create train and test dataset\n",
    "# sorted based on timestamp \n",
    "\n",
    "# extract timestamps for visualization\n",
    "train_datetime_list = list(train_data.index)\n",
    "target_datetime_list = list(short_squeeze_data.index)\n",
    "\n",
    "# reordering the columns: put the prediction column to the last column\n",
    "cols = ['open_price', 'high-price', 'low-price', 'volume','close_price']\n",
    "df_train = train_data[cols]\n",
    "df_target = short_squeeze_data[cols]\n",
    "\n",
    "# check the df column types to ensure they have correct types\n",
    "print(df_train.dtypes)\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='datetime'>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train['close_price'].plot()\n",
    "df_target['close_price'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "open_price     0\n",
       "high-price     0\n",
       "low-price      0\n",
       "volume         0\n",
       "close_price    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding missing values\n",
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "open_price     0\n",
       "high-price     0\n",
       "low-price      0\n",
       "volume         0\n",
       "close_price    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_target.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the ditribution of the features in the train dataset\n",
    "df_std = (df_train - df_train.mean()) / df_train.std()\n",
    "df_std = df_std.melt(var_name='Column', value_name='Normalized')\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "ax = sns.violinplot(x='Column', y='Normalized', data=df_std)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(df_train, df_target, feature_set):\n",
    "    sc = StandardScaler()\n",
    "    train_arr = sc.fit_transform(df_train[feature_set])\n",
    "    target_arr = sc.fit_transform(df_target[feature_set])\n",
    "    return train_arr, target_arr\n",
    "\n",
    "def split(train_arr, train_ratio):\n",
    "    # split the data to train, validate\n",
    "    n = len(train_arr)\n",
    "    train_set = train_arr[:int(n*train_ratio)]\n",
    "    val_set = train_arr[int(n*train_ratio):]\n",
    "    return train_set, val_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Windowing for time series forecasting\n",
    "\n",
    "> Refer to [Data Windowing](https://www.tensorflow.org/tutorials/structured_data/time_series#data_windowing) for more details\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate time windows for time series forecasting with LSTM network\n",
    "def generate_window(dataset, train_window, pred_horizon):\n",
    "    dataset_seq = []\n",
    "    size = len(dataset)\n",
    "    x_arr = []\n",
    "    y_arr = []\n",
    "    for i in range(size - train_window - pred_horizon):\n",
    "        x = dataset[i:(i+train_window), :-1]\n",
    "        y = dataset[i+train_window+pred_horizon-1:i+train_window+pred_horizon, -1]\n",
    "        x_arr.append(x)\n",
    "        y_arr.append(y)\n",
    "\n",
    "    x_tensor = torch.tensor(x_arr).float()\n",
    "    y_tensor = torch.tensor(y_arr).float()\n",
    "    num_features = x_tensor.shape[2]\n",
    "    tensor_dataset = TensorDataset(x_tensor,y_tensor)\n",
    "    batch_size = 100\n",
    "    tensor_dataloader = DataLoader(tensor_dataset, batch_size, False)\n",
    "    dataset_seq = (x_tensor, y_tensor)\n",
    "    return tensor_dataloader, num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# various feature set for model selection\n",
    "feature_set1 = ['open_price', 'high-price', 'low-price', 'volume', 'close_price']\n",
    "feature_set2 = ['open_price', 'high-price', 'low-price', 'close_price']\n",
    "feature_set3 = ['open_price', 'volume', 'close_price']\n",
    "feature_set4 = ['volume', 'close_price']\n",
    "feature_sets = [feature_set1, feature_set1, feature_set3, feature_set4]\n",
    "\n",
    "# let's create sequential training dataset with various traning windows and prediction horizons\n",
    "# given that the times series data has 1-hour resolution\n",
    "# 24hours * (days)\n",
    "train_window_list = 24 * np.array([5, 10, 30])\n",
    "prediction_horizon_list = 24 * np.array([1, 2, 3, 5, 10])\n",
    "\n",
    "\n",
    "train_set, target_set = scale(df_train, df_target, feature_sets[0])\n",
    "train_set , val_set = split(train_set, 0.8)\n",
    "\n",
    "train_window = train_window_list[0]\n",
    "prediction_horizon = prediction_horizon_list[0]\n",
    "\n",
    "train_seq, num_features = generate_window(train_set, train_window, prediction_horizon)\n",
    "val_seq, _ = generate_window(val_set, train_window, prediction_horizon)\n",
    "target_seq, _ = generate_window(target_set, train_window, prediction_horizon)\n",
    "\n",
    "datetime_target = target_datetime_list[train_window+prediction_horizon:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "for dnx, batch in enumerate(train_seq):\n",
    "    x, y = batch\n",
    "    print(x.size(0))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating LSTM Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, seq_length, hidden_size=100, num_layers = 2, output_size=1):\n",
    "        super(LSTM, self).__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.seq_len = seq_length\n",
    "        \n",
    "        self.hidden = None\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=self.input_size,\n",
    "            hidden_size=self.hidden_size,\n",
    "            num_layers=self.num_layers,\n",
    "            dropout=0.2,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        self.linear = nn.Linear(self.hidden_size * self.seq_len, self.output_size)\n",
    "\n",
    "    def init_hidden(self, batch_size, device):\n",
    "        self.hidden_state = torch.zeros(self.num_layers, batch_size ,self.hidden_size).to(device)\n",
    "        self.cell_state = torch.zeros(self.num_layers, batch_size ,self.hidden_size).to(device)\n",
    "        self.hidden = (self.hidden_state, self.cell_state)\n",
    "\n",
    "    def forward(self, x, forecast_timesteps = 0):\n",
    "        batch_size = x.size(0)\n",
    "        print(batch_size)\n",
    "#         if self.hidden is None:\n",
    "#             self.init_hidden(batch_size)\n",
    "#         print(batch_size)\n",
    "#         h_0 = torch.zeros(self.num_layers, batch_size ,self.hidden_size)\n",
    "#         c_0 = torch.zeros(self.num_layers, batch_size ,self.hidden_size)\n",
    "        \n",
    "        lstm_out, self.hidden = self.lstm(\n",
    "                x,\n",
    "                self.hidden\n",
    "            )\n",
    "        \n",
    "        outputs = self.linear(lstm_out.reshape(batch_size,-1))\n",
    "\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traning LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, device, train_seq, val_seq=None, num_epochs=200):\n",
    "#     X_train, y_train = train_seq\n",
    "#     inputs, labels = X_train.to(device), y_train.to(device)\n",
    "#     if val_seq is not None:\n",
    "#         X_val, y_val = val_seq\n",
    "#         inputs_val, labels_val = X_val.to(device), y_val.to(device)\n",
    "\n",
    "    learning_rate = 1e-3\n",
    "    best_loss = np.Inf\n",
    "    val_loss = None\n",
    "    history = dict(train=[], val=[])\n",
    "\n",
    "    criterion = torch.nn.MSELoss().to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for batch_ndx, batch in enumerate(train_seq):\n",
    "            x, y = batch\n",
    "            batch_size = x.size(0)\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "#             print(x.size(0))\n",
    "#             inputs, labels = X_train.to(device), y_train.to(device)\n",
    "            model.init_hidden(batch_size, device)\n",
    "            outputs = model(x)\n",
    "            loss = criterion(outputs, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            train_loss = loss.item()\n",
    "            history['train'].append(train_loss)\n",
    "\n",
    "#             if val_seq is not None:\n",
    "#                 with torch.no_grad():\n",
    "#                     model.eval()\n",
    "\n",
    "#                     model.init_hidden(inputs_val.shape[0], device)\n",
    "#                     pred = model(inputs_val)\n",
    "#                     loss = criterion(pred, labels_val)\n",
    "#                     val_loss = loss.item()\n",
    "#                     history['val'].append(val_loss)\n",
    "#                     if val_loss < best_loss:\n",
    "#                         best_loss = val_loss\n",
    "    #                     best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "            print(f'Epoch {epoch}: train loss {train_loss} val loss {val_loss}')\n",
    "\n",
    "#         if val_loss < 0.05:\n",
    "# #             best_model_wts = copy.deepcopy(model.state_dict())\n",
    "#             break\n",
    "   \n",
    "    return model.eval(), history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "Epoch 0: train loss 0.487871915102005 val loss None\n",
      "100\n",
      "Epoch 0: train loss 0.07698725908994675 val loss None\n",
      "100\n",
      "Epoch 0: train loss 0.023337287828326225 val loss None\n",
      "100\n",
      "Epoch 0: train loss 0.33254751563072205 val loss None\n",
      "100\n",
      "Epoch 0: train loss 0.18081313371658325 val loss None\n",
      "100\n",
      "Epoch 0: train loss 0.0011182560119777918 val loss None\n",
      "100\n",
      "Epoch 0: train loss 0.05464041233062744 val loss None\n",
      "100\n",
      "Epoch 0: train loss 0.16100448369979858 val loss None\n",
      "100\n",
      "Epoch 0: train loss 0.11007589101791382 val loss None\n",
      "100\n",
      "Epoch 0: train loss 0.08874188363552094 val loss None\n",
      "100\n",
      "Epoch 0: train loss 0.03671497106552124 val loss None\n",
      "100\n",
      "Epoch 0: train loss 0.010680302046239376 val loss None\n",
      "100\n",
      "Epoch 0: train loss 0.0019474627915769815 val loss None\n",
      "100\n",
      "Epoch 0: train loss 0.06557377427816391 val loss None\n",
      "100\n",
      "Epoch 0: train loss 0.05609673261642456 val loss None\n",
      "100\n",
      "Epoch 0: train loss 0.06063990294933319 val loss None\n",
      "100\n",
      "Epoch 0: train loss 0.01103318203240633 val loss None\n",
      "100\n",
      "Epoch 0: train loss 0.0028207548893988132 val loss None\n",
      "100\n",
      "Epoch 0: train loss 0.0011436057975515723 val loss None\n",
      "100\n",
      "Epoch 0: train loss 0.0038966238498687744 val loss None\n",
      "100\n",
      "Epoch 0: train loss 0.008438593707978725 val loss None\n",
      "100\n",
      "Epoch 0: train loss 0.010914189741015434 val loss None\n",
      "100\n",
      "Epoch 0: train loss 0.020067427307367325 val loss None\n",
      "100\n",
      "Epoch 0: train loss 0.012944679707288742 val loss None\n",
      "100\n",
      "Epoch 0: train loss 0.005425883922725916 val loss None\n",
      "100\n",
      "Epoch 0: train loss 0.0007229156908579171 val loss None\n",
      "100\n",
      "Epoch 0: train loss 0.008382526226341724 val loss None\n",
      "100\n",
      "Epoch 0: train loss 0.013216782361268997 val loss None\n",
      "100\n",
      "Epoch 0: train loss 0.02267507091164589 val loss None\n",
      "100\n",
      "Epoch 0: train loss 0.03347664698958397 val loss None\n",
      "100\n",
      "Epoch 0: train loss 0.023177755996584892 val loss None\n",
      "100\n",
      "Epoch 0: train loss 0.013830676674842834 val loss None\n",
      "100\n",
      "Epoch 0: train loss 0.024951357394456863 val loss None\n",
      "100\n",
      "Epoch 0: train loss 0.20686332881450653 val loss None\n",
      "100\n",
      "Epoch 0: train loss 0.11363428831100464 val loss None\n",
      "100\n",
      "Epoch 0: train loss 0.027271470054984093 val loss None\n",
      "100\n",
      "Epoch 0: train loss 0.0312705896794796 val loss None\n",
      "100\n",
      "Epoch 0: train loss 0.08333774656057358 val loss None\n",
      "100\n",
      "Epoch 0: train loss 0.014595093205571175 val loss None\n",
      "100\n",
      "Epoch 0: train loss 0.02802813984453678 val loss None\n",
      "100\n",
      "Epoch 0: train loss 0.009739075787365437 val loss None\n",
      "100\n",
      "Epoch 0: train loss 0.04445703700184822 val loss None\n",
      "100\n",
      "Epoch 0: train loss 0.1539974808692932 val loss None\n",
      "100\n",
      "Epoch 0: train loss 0.020380791276693344 val loss None\n",
      "100\n",
      "Epoch 0: train loss 0.05180194601416588 val loss None\n",
      "100\n",
      "Epoch 0: train loss 0.034175675362348557 val loss None\n",
      "100\n",
      "Epoch 0: train loss 0.18198390305042267 val loss None\n",
      "100\n",
      "Epoch 0: train loss 0.7529536485671997 val loss None\n",
      "100\n",
      "Epoch 0: train loss 0.1920679211616516 val loss None\n",
      "72\n",
      "Epoch 0: train loss 0.00344230723567307 val loss None\n",
      "100\n",
      "Epoch 1: train loss 1.565897822380066 val loss None\n",
      "100\n",
      "Epoch 1: train loss 1.1285724639892578 val loss None\n",
      "100\n",
      "Epoch 1: train loss 0.8690621852874756 val loss None\n",
      "100\n",
      "Epoch 1: train loss 0.28906944394111633 val loss None\n",
      "100\n",
      "Epoch 1: train loss 0.16069722175598145 val loss None\n",
      "100\n",
      "Epoch 1: train loss 0.19541750848293304 val loss None\n",
      "100\n",
      "Epoch 1: train loss 0.16132855415344238 val loss None\n",
      "100\n",
      "Epoch 1: train loss 0.1376786082983017 val loss None\n",
      "100\n",
      "Epoch 1: train loss 0.032484158873558044 val loss None\n",
      "100\n",
      "Epoch 1: train loss 0.0032376893796026707 val loss None\n",
      "100\n",
      "Epoch 1: train loss 0.014982594177126884 val loss None\n",
      "100\n",
      "Epoch 1: train loss 0.04812357947230339 val loss None\n",
      "100\n",
      "Epoch 1: train loss 0.08742952346801758 val loss None\n",
      "100\n",
      "Epoch 1: train loss 0.16468852758407593 val loss None\n",
      "100\n",
      "Epoch 1: train loss 0.07492219656705856 val loss None\n",
      "100\n",
      "Epoch 1: train loss 0.020034942775964737 val loss None\n",
      "100\n",
      "Epoch 1: train loss 0.0035289947409182787 val loss None\n",
      "100\n",
      "Epoch 1: train loss 0.023828215897083282 val loss None\n",
      "100\n",
      "Epoch 1: train loss 0.09512759745121002 val loss None\n",
      "100\n",
      "Epoch 1: train loss 0.13176001608371735 val loss None\n",
      "100\n",
      "Epoch 1: train loss 0.13634884357452393 val loss None\n",
      "100\n",
      "Epoch 1: train loss 0.07736912369728088 val loss None\n",
      "100\n",
      "Epoch 1: train loss 0.040324945002794266 val loss None\n",
      "100\n",
      "Epoch 1: train loss 0.00495537556707859 val loss None\n",
      "100\n",
      "Epoch 1: train loss 0.004834141582250595 val loss None\n",
      "100\n",
      "Epoch 1: train loss 0.030411193147301674 val loss None\n",
      "100\n",
      "Epoch 1: train loss 0.08723501116037369 val loss None\n",
      "100\n",
      "Epoch 1: train loss 0.09900014847517014 val loss None\n",
      "100\n",
      "Epoch 1: train loss 0.09127362072467804 val loss None\n",
      "100\n",
      "Epoch 1: train loss 0.08115784823894501 val loss None\n",
      "100\n",
      "Epoch 1: train loss 0.040109165012836456 val loss None\n",
      "100\n",
      "Epoch 1: train loss 0.01639479398727417 val loss None\n",
      "100\n",
      "Epoch 1: train loss 0.016694052144885063 val loss None\n",
      "100\n",
      "Epoch 1: train loss 0.2015513777732849 val loss None\n",
      "100\n",
      "Epoch 1: train loss 0.16614089906215668 val loss None\n",
      "100\n",
      "Epoch 1: train loss 0.03115658648312092 val loss None\n",
      "100\n",
      "Epoch 1: train loss 0.02504320628941059 val loss None\n",
      "100\n",
      "Epoch 1: train loss 0.10692897439002991 val loss None\n",
      "100\n",
      "Epoch 1: train loss 0.25958573818206787 val loss None\n",
      "100\n",
      "Epoch 1: train loss 0.09449701011180878 val loss None\n",
      "100\n",
      "Epoch 1: train loss 0.01839272491633892 val loss None\n",
      "100\n",
      "Epoch 1: train loss 0.033905062824487686 val loss None\n",
      "100\n",
      "Epoch 1: train loss 0.13822391629219055 val loss None\n",
      "100\n",
      "Epoch 1: train loss 0.02068127878010273 val loss None\n",
      "100\n",
      "Epoch 1: train loss 0.03727968409657478 val loss None\n",
      "100\n",
      "Epoch 1: train loss 0.07629913836717606 val loss None\n",
      "100\n",
      "Epoch 1: train loss 0.05078951269388199 val loss None\n",
      "100\n",
      "Epoch 1: train loss 0.890487790107727 val loss None\n",
      "100\n",
      "Epoch 1: train loss 0.4615517258644104 val loss None\n",
      "72\n",
      "Epoch 1: train loss 0.04694046452641487 val loss None\n",
      "100\n",
      "Epoch 2: train loss 2.600515365600586 val loss None\n",
      "100\n",
      "Epoch 2: train loss 1.7787771224975586 val loss None\n",
      "100\n",
      "Epoch 2: train loss 1.2586228847503662 val loss None\n",
      "100\n",
      "Epoch 2: train loss 0.3449249863624573 val loss None\n",
      "100\n",
      "Epoch 2: train loss 0.17576739192008972 val loss None\n",
      "100\n",
      "Epoch 2: train loss 0.13541929423809052 val loss None\n",
      "100\n",
      "Epoch 2: train loss 0.03873072937130928 val loss None\n",
      "100\n",
      "Epoch 2: train loss 0.01421243418008089 val loss None\n",
      "100\n",
      "Epoch 2: train loss 0.010141702368855476 val loss None\n",
      "100\n",
      "Epoch 2: train loss 0.04099861904978752 val loss None\n",
      "100\n",
      "Epoch 2: train loss 0.09087419509887695 val loss None\n",
      "100\n",
      "Epoch 2: train loss 0.07575137168169022 val loss None\n",
      "100\n",
      "Epoch 2: train loss 0.05507699027657509 val loss None\n",
      "100\n",
      "Epoch 2: train loss 0.0667489618062973 val loss None\n",
      "100\n",
      "Epoch 2: train loss 0.012127963826060295 val loss None\n",
      "100\n",
      "Epoch 2: train loss 0.001388861215673387 val loss None\n",
      "100\n",
      "Epoch 2: train loss 0.0850425511598587 val loss None\n",
      "100\n",
      "Epoch 2: train loss 0.09619585424661636 val loss None\n",
      "100\n",
      "Epoch 2: train loss 0.09084741026163101 val loss None\n",
      "100\n",
      "Epoch 2: train loss 0.08147023618221283 val loss None\n",
      "100\n",
      "Epoch 2: train loss 0.07034613192081451 val loss None\n",
      "100\n",
      "Epoch 2: train loss 0.0407879613339901 val loss None\n",
      "100\n",
      "Epoch 2: train loss 0.025603754445910454 val loss None\n",
      "100\n",
      "Epoch 2: train loss 0.004821303766220808 val loss None\n",
      "100\n",
      "Epoch 2: train loss 0.0010537139605730772 val loss None\n",
      "100\n",
      "Epoch 2: train loss 0.013115701265633106 val loss None\n",
      "100\n",
      "Epoch 2: train loss 0.05230500549077988 val loss None\n",
      "100\n",
      "Epoch 2: train loss 0.06643398106098175 val loss None\n",
      "100\n",
      "Epoch 2: train loss 0.06807874888181686 val loss None\n",
      "100\n",
      "Epoch 2: train loss 0.06932947784662247 val loss None\n",
      "100\n",
      "Epoch 2: train loss 0.03944935277104378 val loss None\n",
      "100\n",
      "Epoch 2: train loss 0.02038670890033245 val loss None\n",
      "100\n",
      "Epoch 2: train loss 0.02326572686433792 val loss None\n",
      "100\n",
      "Epoch 2: train loss 0.2530398368835449 val loss None\n",
      "100\n",
      "Epoch 2: train loss 0.2295609563589096 val loss None\n",
      "100\n",
      "Epoch 2: train loss 0.03675217181444168 val loss None\n",
      "100\n",
      "Epoch 2: train loss 0.01249462366104126 val loss None\n",
      "100\n",
      "Epoch 2: train loss 0.17096629738807678 val loss None\n",
      "100\n",
      "Epoch 2: train loss 0.7614787220954895 val loss None\n",
      "100\n",
      "Epoch 2: train loss 0.2036220133304596 val loss None\n",
      "100\n",
      "Epoch 2: train loss 0.026435375213623047 val loss None\n",
      "100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: train loss 0.01713350974023342 val loss None\n",
      "100\n",
      "Epoch 2: train loss 0.16883791983127594 val loss None\n",
      "100\n",
      "Epoch 2: train loss 0.06318677961826324 val loss None\n",
      "100\n",
      "Epoch 2: train loss 0.09031947702169418 val loss None\n",
      "100\n",
      "Epoch 2: train loss 0.05515911802649498 val loss None\n",
      "100\n",
      "Epoch 2: train loss 0.0851076990365982 val loss None\n",
      "100\n",
      "Epoch 2: train loss 0.9656358361244202 val loss None\n",
      "100\n",
      "Epoch 2: train loss 0.5214938521385193 val loss None\n",
      "72\n",
      "Epoch 2: train loss 0.09352242946624756 val loss None\n",
      "100\n",
      "Epoch 3: train loss 2.0782294273376465 val loss None\n",
      "100\n",
      "Epoch 3: train loss 1.4546148777008057 val loss None\n",
      "100\n",
      "Epoch 3: train loss 1.0012962818145752 val loss None\n",
      "100\n",
      "Epoch 3: train loss 0.24073214828968048 val loss None\n",
      "100\n",
      "Epoch 3: train loss 0.09147245436906815 val loss None\n",
      "100\n",
      "Epoch 3: train loss 0.045266736298799515 val loss None\n",
      "100\n",
      "Epoch 3: train loss 0.0038614151999354362 val loss None\n",
      "100\n",
      "Epoch 3: train loss 0.02440253272652626 val loss None\n",
      "100\n",
      "Epoch 3: train loss 0.139179065823555 val loss None\n",
      "100\n",
      "Epoch 3: train loss 0.1579497754573822 val loss None\n",
      "100\n",
      "Epoch 3: train loss 0.14551155269145966 val loss None\n",
      "100\n",
      "Epoch 3: train loss 0.06048239395022392 val loss None\n",
      "100\n",
      "Epoch 3: train loss 0.016638988628983498 val loss None\n",
      "100\n",
      "Epoch 3: train loss 0.016187936067581177 val loss None\n",
      "100\n",
      "Epoch 3: train loss 0.001309693674556911 val loss None\n",
      "100\n",
      "Epoch 3: train loss 0.011447522789239883 val loss None\n",
      "100\n",
      "Epoch 3: train loss 0.08712763339281082 val loss None\n",
      "100\n",
      "Epoch 3: train loss 0.11846484988927841 val loss None\n",
      "100\n",
      "Epoch 3: train loss 0.11401647329330444 val loss None\n",
      "100\n",
      "Epoch 3: train loss 0.10930662602186203 val loss None\n",
      "100\n",
      "Epoch 3: train loss 0.09796205163002014 val loss None\n",
      "100\n",
      "Epoch 3: train loss 0.06577686220407486 val loss None\n",
      "100\n",
      "Epoch 3: train loss 0.050975605845451355 val loss None\n",
      "100\n",
      "Epoch 3: train loss 0.021224092692136765 val loss None\n",
      "100\n",
      "Epoch 3: train loss 0.002656531287357211 val loss None\n",
      "100\n",
      "Epoch 3: train loss 0.0014128339244052768 val loss None\n",
      "100\n",
      "Epoch 3: train loss 0.02865137718617916 val loss None\n",
      "100\n",
      "Epoch 3: train loss 0.053383320569992065 val loss None\n",
      "100\n",
      "Epoch 3: train loss 0.07761338353157043 val loss None\n",
      "100\n",
      "Epoch 3: train loss 0.10670820623636246 val loss None\n",
      "100\n",
      "Epoch 3: train loss 0.09123130887746811 val loss None\n",
      "100\n",
      "Epoch 3: train loss 0.0755891352891922 val loss None\n",
      "100\n",
      "Epoch 3: train loss 0.09158840030431747 val loss None\n",
      "100\n",
      "Epoch 3: train loss 0.40676504373550415 val loss None\n",
      "100\n",
      "Epoch 3: train loss 0.3580256700515747 val loss None\n",
      "100\n",
      "Epoch 3: train loss 0.10166467726230621 val loss None\n",
      "100\n",
      "Epoch 3: train loss 0.021533628925681114 val loss None\n",
      "100\n",
      "Epoch 3: train loss 0.35260963439941406 val loss None\n",
      "100\n",
      "Epoch 3: train loss 0.7564324736595154 val loss None\n",
      "100\n",
      "Epoch 3: train loss 0.35768842697143555 val loss None\n",
      "100\n",
      "Epoch 3: train loss 0.1822241097688675 val loss None\n",
      "100\n",
      "Epoch 3: train loss 0.035084910690784454 val loss None\n",
      "100\n",
      "Epoch 3: train loss 0.404266893863678 val loss None\n",
      "100\n",
      "Epoch 3: train loss 0.3117408752441406 val loss None\n",
      "100\n",
      "Epoch 3: train loss 0.4449532628059387 val loss None\n",
      "100\n",
      "Epoch 3: train loss 0.3858658969402313 val loss None\n",
      "100\n",
      "Epoch 3: train loss 0.09880521893501282 val loss None\n",
      "100\n",
      "Epoch 3: train loss 0.5729029178619385 val loss None\n",
      "100\n",
      "Epoch 3: train loss 0.5658438205718994 val loss None\n",
      "72\n",
      "Epoch 3: train loss 0.2676050662994385 val loss None\n",
      "100\n",
      "Epoch 4: train loss 2.065840005874634 val loss None\n",
      "100\n",
      "Epoch 4: train loss 1.6316657066345215 val loss None\n",
      "100\n",
      "Epoch 4: train loss 1.245127558708191 val loss None\n",
      "100\n",
      "Epoch 4: train loss 0.45529937744140625 val loss None\n",
      "100\n",
      "Epoch 4: train loss 0.30255362391471863 val loss None\n",
      "100\n",
      "Epoch 4: train loss 0.2622304856777191 val loss None\n",
      "100\n",
      "Epoch 4: train loss 0.11118266731500626 val loss None\n",
      "100\n",
      "Epoch 4: train loss 0.051285650581121445 val loss None\n",
      "100\n",
      "Epoch 4: train loss 0.0008464951533824205 val loss None\n",
      "100\n",
      "Epoch 4: train loss 0.018089044839143753 val loss None\n",
      "100\n",
      "Epoch 4: train loss 0.07593794912099838 val loss None\n",
      "100\n",
      "Epoch 4: train loss 0.09277200698852539 val loss None\n",
      "100\n",
      "Epoch 4: train loss 0.09141964465379715 val loss None\n",
      "100\n",
      "Epoch 4: train loss 0.11442700028419495 val loss None\n",
      "100\n",
      "Epoch 4: train loss 0.03661360591650009 val loss None\n",
      "100\n",
      "Epoch 4: train loss 0.013490617275238037 val loss None\n",
      "100\n",
      "Epoch 4: train loss 0.03722133859992027 val loss None\n",
      "100\n",
      "Epoch 4: train loss 0.0489986427128315 val loss None\n",
      "100\n",
      "Epoch 4: train loss 0.06259249895811081 val loss None\n",
      "100\n",
      "Epoch 4: train loss 0.0707096979022026 val loss None\n",
      "100\n",
      "Epoch 4: train loss 0.08097624778747559 val loss None\n",
      "100\n",
      "Epoch 4: train loss 0.07050080597400665 val loss None\n",
      "100\n",
      "Epoch 4: train loss 0.07023491710424423 val loss None\n",
      "100\n",
      "Epoch 4: train loss 0.04238677769899368 val loss None\n",
      "100\n",
      "Epoch 4: train loss 0.014601144008338451 val loss None\n",
      "100\n",
      "Epoch 4: train loss 0.0009878032142296433 val loss None\n",
      "100\n",
      "Epoch 4: train loss 0.015198878012597561 val loss None\n",
      "100\n",
      "Epoch 4: train loss 0.037104830145835876 val loss None\n",
      "100\n",
      "Epoch 4: train loss 0.06713418662548065 val loss None\n",
      "100\n",
      "Epoch 4: train loss 0.09465103596448898 val loss None\n",
      "100\n",
      "Epoch 4: train loss 0.07864296436309814 val loss None\n",
      "100\n",
      "Epoch 4: train loss 0.0576632134616375 val loss None\n",
      "100\n",
      "Epoch 4: train loss 0.06902089715003967 val loss None\n",
      "100\n",
      "Epoch 4: train loss 0.3352871239185333 val loss None\n",
      "100\n",
      "Epoch 4: train loss 0.3020572066307068 val loss None\n",
      "100\n",
      "Epoch 4: train loss 0.09238629788160324 val loss None\n",
      "100\n",
      "Epoch 4: train loss 0.012775366194546223 val loss None\n",
      "100\n",
      "Epoch 4: train loss 0.3030248284339905 val loss None\n",
      "100\n",
      "Epoch 4: train loss 0.6601158976554871 val loss None\n",
      "100\n",
      "Epoch 4: train loss 0.45293256640434265 val loss None\n",
      "100\n",
      "Epoch 4: train loss 0.2863726317882538 val loss None\n",
      "100\n",
      "Epoch 4: train loss 0.09571626782417297 val loss None\n",
      "100\n",
      "Epoch 4: train loss 0.553707480430603 val loss None\n",
      "100\n",
      "Epoch 4: train loss 0.6251688599586487 val loss None\n",
      "100\n",
      "Epoch 4: train loss 0.9367184042930603 val loss None\n",
      "100\n",
      "Epoch 4: train loss 1.051887035369873 val loss None\n",
      "100\n",
      "Epoch 4: train loss 0.6161803007125854 val loss None\n",
      "100\n",
      "Epoch 4: train loss 0.05343884974718094 val loss None\n",
      "100\n",
      "Epoch 4: train loss 0.19254647195339203 val loss None\n",
      "72\n",
      "Epoch 4: train loss 0.17187221348285675 val loss None\n",
      "100\n",
      "Epoch 5: train loss 2.0572922229766846 val loss None\n",
      "100\n",
      "Epoch 5: train loss 1.694047451019287 val loss None\n",
      "100\n",
      "Epoch 5: train loss 1.2187702655792236 val loss None\n",
      "100\n",
      "Epoch 5: train loss 0.3598386347293854 val loss None\n",
      "100\n",
      "Epoch 5: train loss 0.21774180233478546 val loss None\n",
      "100\n",
      "Epoch 5: train loss 0.09368222206830978 val loss None\n",
      "100\n",
      "Epoch 5: train loss 0.01294730231165886 val loss None\n",
      "100\n",
      "Epoch 5: train loss 0.1527857482433319 val loss None\n",
      "100\n",
      "Epoch 5: train loss 0.4121256172657013 val loss None\n",
      "100\n",
      "Epoch 5: train loss 0.29564541578292847 val loss None\n",
      "100\n",
      "Epoch 5: train loss 0.1721799075603485 val loss None\n",
      "100\n",
      "Epoch 5: train loss 0.03955892100930214 val loss None\n",
      "100\n",
      "Epoch 5: train loss 0.0018312516622245312 val loss None\n",
      "100\n",
      "Epoch 5: train loss 0.005305837374180555 val loss None\n",
      "100\n",
      "Epoch 5: train loss 0.03542112931609154 val loss None\n",
      "100\n",
      "Epoch 5: train loss 0.0641523227095604 val loss None\n",
      "100\n",
      "Epoch 5: train loss 0.09943104535341263 val loss None\n",
      "100\n",
      "Epoch 5: train loss 0.15964044630527496 val loss None\n",
      "100\n",
      "Epoch 5: train loss 0.16547881066799164 val loss None\n",
      "100\n",
      "Epoch 5: train loss 0.16847634315490723 val loss None\n",
      "100\n",
      "Epoch 5: train loss 0.15558773279190063 val loss None\n",
      "100\n",
      "Epoch 5: train loss 0.11436538398265839 val loss None\n",
      "100\n",
      "Epoch 5: train loss 0.09580691903829575 val loss None\n",
      "100\n",
      "Epoch 5: train loss 0.04986100271344185 val loss None\n",
      "100\n",
      "Epoch 5: train loss 0.015548107214272022 val loss None\n",
      "100\n",
      "Epoch 5: train loss 0.0011768558761104941 val loss None\n",
      "100\n",
      "Epoch 5: train loss 0.01387728936970234 val loss None\n",
      "100\n",
      "Epoch 5: train loss 0.033557213842868805 val loss None\n",
      "100\n",
      "Epoch 5: train loss 0.062434710562229156 val loss None\n",
      "100\n",
      "Epoch 5: train loss 0.09987790137529373 val loss None\n",
      "100\n",
      "Epoch 5: train loss 0.09366931021213531 val loss None\n",
      "100\n",
      "Epoch 5: train loss 0.09217122942209244 val loss None\n",
      "100\n",
      "Epoch 5: train loss 0.11649009585380554 val loss None\n",
      "100\n",
      "Epoch 5: train loss 0.43171966075897217 val loss None\n",
      "100\n",
      "Epoch 5: train loss 0.28321993350982666 val loss None\n",
      "100\n",
      "Epoch 5: train loss 0.08253341168165207 val loss None\n",
      "100\n",
      "Epoch 5: train loss 0.04647265002131462 val loss None\n",
      "100\n",
      "Epoch 5: train loss 0.44199323654174805 val loss None\n",
      "100\n",
      "Epoch 5: train loss 0.5970218777656555 val loss None\n",
      "100\n",
      "Epoch 5: train loss 0.4123920798301697 val loss None\n",
      "100\n",
      "Epoch 5: train loss 0.33189845085144043 val loss None\n",
      "100\n",
      "Epoch 5: train loss 0.16933190822601318 val loss None\n",
      "100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: train loss 0.7702118754386902 val loss None\n",
      "100\n",
      "Epoch 5: train loss 0.7299423217773438 val loss None\n",
      "100\n",
      "Epoch 5: train loss 1.099672555923462 val loss None\n",
      "100\n",
      "Epoch 5: train loss 1.2656232118606567 val loss None\n",
      "100\n",
      "Epoch 5: train loss 0.8257370591163635 val loss None\n",
      "100\n",
      "Epoch 5: train loss 0.021341990679502487 val loss None\n",
      "100\n",
      "Epoch 5: train loss 0.031852830201387405 val loss None\n",
      "72\n",
      "Epoch 5: train loss 0.026914140209555626 val loss None\n",
      "100\n",
      "Epoch 6: train loss 0.318154513835907 val loss None\n",
      "100\n",
      "Epoch 6: train loss 0.3054082691669464 val loss None\n",
      "100\n",
      "Epoch 6: train loss 0.2931837737560272 val loss None\n",
      "100\n",
      "Epoch 6: train loss 0.06725379824638367 val loss None\n",
      "100\n",
      "Epoch 6: train loss 0.12912623584270477 val loss None\n",
      "100\n",
      "Epoch 6: train loss 0.1234516054391861 val loss None\n",
      "100\n",
      "Epoch 6: train loss 0.0072599067352712154 val loss None\n",
      "100\n",
      "Epoch 6: train loss 0.021822642534971237 val loss None\n",
      "100\n",
      "Epoch 6: train loss 0.16082483530044556 val loss None\n",
      "100\n",
      "Epoch 6: train loss 0.16298365592956543 val loss None\n",
      "100\n",
      "Epoch 6: train loss 0.1622564047574997 val loss None\n",
      "100\n",
      "Epoch 6: train loss 0.08711917698383331 val loss None\n",
      "100\n",
      "Epoch 6: train loss 0.03106791339814663 val loss None\n",
      "100\n",
      "Epoch 6: train loss 0.019920827820897102 val loss None\n",
      "100\n",
      "Epoch 6: train loss 0.015970773994922638 val loss None\n",
      "100\n",
      "Epoch 6: train loss 0.033674322068691254 val loss None\n",
      "100\n",
      "Epoch 6: train loss 0.18590548634529114 val loss None\n",
      "100\n",
      "Epoch 6: train loss 0.13991820812225342 val loss None\n",
      "100\n",
      "Epoch 6: train loss 0.06810664385557175 val loss None\n",
      "100\n",
      "Epoch 6: train loss 0.06042329594492912 val loss None\n",
      "100\n",
      "Epoch 6: train loss 0.04259907454252243 val loss None\n",
      "100\n",
      "Epoch 6: train loss 0.021136781200766563 val loss None\n",
      "100\n",
      "Epoch 6: train loss 0.010859950445592403 val loss None\n",
      "100\n",
      "Epoch 6: train loss 0.0008211515378206968 val loss None\n",
      "100\n",
      "Epoch 6: train loss 0.006200345698744059 val loss None\n",
      "100\n",
      "Epoch 6: train loss 0.017511282116174698 val loss None\n",
      "100\n",
      "Epoch 6: train loss 0.04413242265582085 val loss None\n",
      "100\n",
      "Epoch 6: train loss 0.03134770691394806 val loss None\n",
      "100\n",
      "Epoch 6: train loss 0.027238696813583374 val loss None\n",
      "100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-8ed6a705f30c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Training loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-65-755e0ef351d5>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, device, train_seq, val_seq, num_epochs)\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m             \u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "torch.cuda.empty_cache()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "\n",
    "model = LSTM(input_size=num_features, seq_length=train_window)\n",
    "model.to(device)\n",
    "\n",
    "model, history = train_model(model, device, train_seq)\n",
    "\n",
    "plt.plot(history['train'], label=\"Training loss\")\n",
    "plt.plot(history['val'], label=\"Test loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, losses = [], []\n",
    "criterion = nn.L1Loss(reduction='sum').to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for i in range(X_test.shape[0]):\n",
    "        x_i = X_test[i:i+1]\n",
    "        y_i = y_test[i:i+1]\n",
    "        x_i.to(device)\n",
    "        model.init_hidden(x_i.shape[0])\n",
    "        y_pred = model(x_i)\n",
    "        predictions.append(y_pred.cpu().numpy().flatten())\n",
    "        loss = criterion(y_pred, y_i)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "truth = y_test.cpu().numpy().flatten()\n",
    "predictions = np.array(predictions).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(datetime_target,predictions, label=\"Predictions\")\n",
    "plt.plot(datetime_target, truth, label=\"Truth\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(datetime_target ,losses, label=\"Prediction Loss\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_index = 0\n",
    "for train_window in train_window_list:\n",
    "    for prediction_horizon in prediction_horizon_list:\n",
    "        for feature_set in feature_sets:\n",
    "\n",
    "            train_set, target_set = scale(df_train, df_target, feature_set)\n",
    "            train_set , val_set = split(train_set, 0.8)\n",
    "\n",
    "            train_seq, num_features = generate_window(train_set, train_window, prediction_horizon)\n",
    "            val_seq, _ = generate_window(val_set, train_window, prediction_horizon)\n",
    "            target_seq, _ = generate_window(target_set, train_window, prediction_horizon)\n",
    "\n",
    "            datetime_target = test_datetime_list[train_window+prediction_horizon:]\n",
    "\n",
    "            model = LSTM(input_size=num_features, seq_length=train_window)\n",
    "            model = model.to(device)\n",
    "\n",
    "            model, history = train_model(model, device, train_seq, val_seq)\n",
    "            model_index += 1\n",
    "\n",
    "            print('Saving...')\n",
    "            state = {\n",
    "                'model': model,\n",
    "                'feature_set': feature_set,\n",
    "                'history': history,\n",
    "                'pred_horizon': prediction_horizon,\n",
    "                'train_window': train_window\n",
    "            }\n",
    "\n",
    "            if not os.path.isdir('checkpoint'):\n",
    "                os.mkdir('checkpoint')\n",
    "            torch.save(state, f'./checkpoint/train_{model_index}.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
